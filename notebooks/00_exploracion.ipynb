{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ee4b25c",
   "metadata": {},
   "source": [
    "# Notebook: Exploración y scripts iniciales\n",
    "\n",
    "Este notebook contiene celdas de ejemplo para:\n",
    "- Crear la jerarquía de carpetas del proyecto\n",
    "- Generar un manifest de videos\n",
    "- Extraer frames y preparar datos\n",
    "- Ejemplos de Dataset y DataLoader (esqueleto)\n",
    "\n",
    "Sigue el README del repo para convenciones y formatos de anotación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c345d8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 1: Creación de estructura de carpetas (script de ejemplo)\n",
    "\n",
    "import os\n",
    "\n",
    "def create_project_dirs(root):\n",
    "    dirs = [\n",
    "        'data/raw', 'data/processed', 'data/annotations',\n",
    "        'src/data', 'src/models', 'src/training', 'src/utils',\n",
    "        'notebooks', 'experiments', 'models', 'logs', 'scripts', 'tests', 'docs'\n",
    "    ]\n",
    "    for d in dirs:\n",
    "        path = os.path.join(root, d)\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "    print('Directorios creados o existentes:')\n",
    "    for d in dirs:\n",
    "        print('-', d)\n",
    "\n",
    "# Uso:\n",
    "# create_project_dirs('..')  # ajustar al path deseado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec350bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 2: Recolección y manifest de videos (ejemplo simple)\n",
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "\n",
    "\n",
    "def file_checksum(path, chunk_size=8192):\n",
    "    h = hashlib.sha256()\n",
    "    with open(path, 'rb') as f:\n",
    "        for chunk in iter(lambda: f.read(chunk_size), b''):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "\n",
    "def build_manifest(videos_dir, out_json='manifest.json'):\n",
    "    entries = []\n",
    "    for fname in os.listdir(videos_dir):\n",
    "        if not fname.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
    "            continue\n",
    "        p = os.path.join(videos_dir, fname)\n",
    "        size = os.path.getsize(p)\n",
    "        chk = file_checksum(p)\n",
    "        entries.append({'file': p, 'size': size, 'sha256': chk})\n",
    "    with open(out_json, 'w', encoding='utf8') as f:\n",
    "        json.dump(entries, f, indent=2)\n",
    "    print(f'Manifest creado: {out_json} (entries: {len(entries)})')\n",
    "\n",
    "# Uso:\n",
    "# build_manifest('data/raw', out_json='data/manifest.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c9478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 4: Extracción de frames (ffmpeg/opencv) — ejemplo\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "\n",
    "def extract_frames_cv(video_path, out_dir, fps=1):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError('No se puede abrir video: %s' % video_path)\n",
    "    video_fps = cap.get(cv2.CAP_PROP_FPS) or 30\n",
    "    frame_interval = max(1, int(round(video_fps / fps)))\n",
    "    i = 0\n",
    "    saved = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if i % frame_interval == 0:\n",
    "            out_path = os.path.join(out_dir, f'frame_{saved:06d}.jpg')\n",
    "            cv2.imwrite(out_path, frame)\n",
    "            saved += 1\n",
    "        i += 1\n",
    "    cap.release()\n",
    "    return saved\n",
    "\n",
    "# Uso:\n",
    "# extract_frames_cv('data/raw/video.mp4', 'data/processed/video_frames', fps=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4493522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section: Ejemplo de Dataset PyTorch (esqueleto)\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "class VideoFramesDataset(Dataset):\n",
    "    def __init__(self, frames_root, transform=None, seq_len=16):\n",
    "        self.frames_root = frames_root\n",
    "        # frames_root is expected to contain subfolders por clip\n",
    "        self.clips = [os.path.join(frames_root, d) for d in os.listdir(frames_root) if os.path.isdir(os.path.join(frames_root, d))]\n",
    "        self.transform = transform\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.clips)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        clip_folder = self.clips[idx]\n",
    "        frames = sorted([os.path.join(clip_folder, f) for f in os.listdir(clip_folder) if f.endswith('.jpg')])\n",
    "        # TODO: cargar secuencia de longitud seq_len, aplicar transformaciones y devolver tensor [C, T, H, W]\n",
    "        imgs = [Image.open(p).convert('RGB') for p in frames[:self.seq_len]]\n",
    "        if self.transform:\n",
    "            imgs = [self.transform(img) for img in imgs]\n",
    "        # stack to tensor [T, C, H, W] -> permute to [C, T, H, W]\n",
    "        imgs = torch.stack(imgs).permute(1, 0, 2, 3)\n",
    "        label = 0  # placeholder\n",
    "        return imgs, label\n",
    "\n",
    "# Uso: dataset = VideoFramesDataset('data/processed/clips', transform=...)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
